{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "61199b96-ce0f-45f7-ae19-5ee9cf171fbb",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.130990Z",
     "start_time": "2024-02-25T05:21:27.070115Z"
    }
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e3b6514-ae47-4e20-8172-4cfc8aa40389",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.189738Z",
     "start_time": "2024-02-25T05:21:27.127506Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import importlib\n",
    "import kfp\n",
    "from kfp import dsl, compiler\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components.v1.model import ModelUploadOp,ModelExportOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ea92e77-5b4a-44d3-8013-6038ab14f368",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.215837Z",
     "start_time": "2024-02-25T05:21:27.160739Z"
    }
   },
   "outputs": [],
   "source": [
    "NOTEBOOK = 'pipeline_babyweight'\n",
    "PROJECT = 'babyweight-mlops'\n",
    "REGION = \"us-central1\"\n",
    "BUCKET = 'mlops_exp_prod_babyweight'\n",
    "APPNAME = \"babyweight\"\n",
    "BQ_DATASET = \"babyweight\"\n",
    "GOOGLE_APPLICATION_CREDENTIALS = '/Users/zacharynguyen/Documents/GitHub/End-to-end-MLOps-with-VertexAI/auth/babyweight-mlops-a0f3cc4a4260.json'\n",
    "\n",
    "os.environ[\"REGION\"] = REGION\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b32f7b-17fd-423e-b73f-421657fb8da0",
   "metadata": {},
   "source": [
    "## 1. Construct the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa10f19e-5c92-4277-9981-1f895d0d51f1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.313013Z",
     "start_time": "2024-02-25T05:21:27.205344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'src.pipeline.prepare_data_component' from '/Users/zacharynguyen/Documents/GitHub/End-to-end-MLOps-with-VertexAI/src/pipeline/prepare_data_component.py'>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.pipeline import prepare_data_component\n",
    "#from src_v1.pipeline import bqml_component\n",
    "#from src_v1.pipeline import custom_model_component\n",
    "#from src_v1.pipeline import model_selection_component\n",
    "\n",
    "importlib.reload(prepare_data_component)\n",
    "#importlib.reload(bqml_component)\n",
    "#importlib.reload(custom_model_component)\n",
    "#importlib.reload(model_selection_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0f50420b-0269-4ba4-9975-4e4f4a491dc1",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.501314Z",
     "start_time": "2024-02-25T05:21:27.315845Z"
    }
   },
   "outputs": [],
   "source": [
    "PIPELINE_URI = f\"gs://{BUCKET}/{APPNAME}\"\n",
    "TRAINING_PIPELINE_DISPLAY_NAME = f\"{APPNAME}-training-pipeline\"\n",
    "\n",
    "SOURCE_BQ_TABLE_ID = \"bigquery-public-data.samples.natality\"\n",
    "LIMIT = 25000\n",
    "\n",
    "\n",
    "#TRAINING_BQ_TABLE_ID = f\"{SOURCE_BQ_TABLE_ID}_prepped_limit_{LIMIT}\" \n",
    "#DATASET_DISPLAY_NAME= f\"babyweight_prepped_limit_{LIMIT}_dataset\"\n",
    "\n",
    "BQML_MODEL_NAME = f\"bqml_dnn_model_{APPNAME}\"\n",
    "BQML_MODEL_ID = f\"{PROJECT}.{BQ_DATASET}.{BQML_MODEL_NAME}\"\n",
    "BQML_TRAININGS_URI = f\"{PIPELINE_URI}/bqml-trainings\"\n",
    "BQML_MODEL_OUTPUT_DIR = f\"{BQML_TRAININGS_URI}/{BQML_MODEL_NAME}\"\n",
    "\n",
    "CUSTOM_MODEL_NAME = f\"custom_dnn_model_{APPNAME}\"\n",
    "CUSTOM_TRAININGS_URI = f\"{PIPELINE_URI}/custom-trainings\"\n",
    "CUSTOM_MODEL_OUTPUT_DIR = f\"{CUSTOM_TRAININGS_URI}/{CUSTOM_MODEL_NAME}\"\n",
    "TRAINING_REPLICA_COUNT = 1\n",
    "TRAINING_MACHINE_TYPE = \"n1-highmem-16\"\n",
    "TRAINING_ACCELERATOR_TYPE = \"NVIDIA_TESLA_K80\"\n",
    "TRAINING_ACCELERATOR_COUNT = 4\n",
    "\n",
    "#TENSORBOARD_INSTANCE = tb.resource_name\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 256\n",
    "HIDDEN_UNITS = \"128,64,16\"\n",
    "DROPOUT_RATE = 0.4\n",
    "LEARNING_RATE = 0.01\n",
    "NUM_EMBEDS = 14\n",
    "PARAMETERS_DICT = {\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"hidden_units\": HIDDEN_UNITS,\n",
    "    \"dropout_rate\": DROPOUT_RATE,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"num_embeds\": NUM_EMBEDS,\n",
    "}\n",
    "\n",
    "THRESHOLDS_DICT = {\"mse\": 3.0}\n",
    "ENDPOINT_DISPLAY_NAME = f\"endpoint_{APPNAME}\"\n",
    "\n",
    "DEPLOY_IMAGE=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest\"\n",
    "DEPLOY_MACHINE_TYPE = \"n1-highmem-16\"\n",
    "DEPLOY_MIN_REPLICA_COUNT = 1\n",
    "DEPLOY_MAX_REPLICA_COUNT = 2\n",
    "\n",
    "#EXPLANATION_PARAMATERS = {\"sampledShapleyAttribution\": {\"pathCount\": 10}}\n",
    "#EXPLANATION_METADATA_JSON_PATH = f\"{CUSTOM_TRAININGS_URI[5:]}/explanation_metadata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d1463ba6-acbb-4a5c-97fa-2874a3778764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.528358Z",
     "start_time": "2024-02-25T05:21:27.348622Z"
    }
   },
   "outputs": [],
   "source": [
    "#from google_cloud_pipeline_components.v1.custom_job import create_custom_training_job_op_from_component\n",
    "#\n",
    "#custom_model_training_op = create_custom_training_job_op_from_component(\n",
    "#    component_spec=custom_model_component.train_evaluate_custom_model_op, \n",
    "#    replica_count=TRAINING_REPLICA_COUNT,\n",
    "#    machine_type=TRAINING_MACHINE_TYPE,\n",
    "#    accelerator_type=TRAINING_ACCELERATOR_TYPE,\n",
    "#    accelerator_count=TRAINING_ACCELERATOR_COUNT,\n",
    "#    service_account=SERVICE_ACCOUNT,\n",
    "#    tensorboard=TENSORBOARD_INSTANCE,\n",
    "#    base_output_directory=BASE_OUTPUT_DIR\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1a9c9292-2240-4218-bd94-cf3fd961b0e8",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.619101Z",
     "start_time": "2024-02-25T05:21:27.382092Z"
    }
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(name = APPNAME, pipeline_root = PIPELINE_URI)\n",
    "def vertex_ai_pipeline(\n",
    "    project: str=PROJECT,\n",
    "    region: str=REGION,\n",
    "):\n",
    "    #from kfp.v2.components import importer_node\n",
    "    #from google_cloud_pipeline_components.types import artifact_types\n",
    "    #from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "    #from google_cloud_pipeline_components.v1.endpoint import EndpointCreateOp\n",
    "    #from google_cloud_pipeline_components.v1.endpoint import ModelDeployOp \n",
    "    #from google_cloud_pipeline_components.v1.batch_predict_job import ModelBatchPredictOp\n",
    "    #from google_cloud_pipeline_components.v1.bigquery import BigqueryCreateModelJobOp\n",
    "    #from google_cloud_pipeline_components.v1.bigquery import BigqueryEvaluateModelJobOp\n",
    "    #from google_cloud_pipeline_components.v1.bigquery import BigqueryExportModelJobOp\n",
    "    #from google_cloud_pipeline_components import aiplatform as gcpc_aip\n",
    "    \n",
    "    ##################################\n",
    "    data_preparing_task = prepare_data_component.bq_table_prep_op(\n",
    "        project=project,\n",
    "        region=region,\n",
    "        source_bq_table_id=SOURCE_BQ_TABLE_ID,\n",
    "        out_bq_dataset_id = f\"{PROJECT}.{BQ_DATASET}\",\n",
    "        limit=LIMIT, \n",
    "    ).set_display_name('prepped-bq-table-create')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0171e541-aaef-45e1-89f7-f55fb816b7cc",
   "metadata": {},
   "source": [
    "## 2. Compile the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "99c4fc30-b850-4542-b2a0-0e3c3b076f06",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.830895Z",
     "start_time": "2024-02-25T05:21:27.428307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new (local) directory to store the complied file\n",
    "DIR = f\"temp\"\n",
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "70408218-fe17-4c63-b102-9d3bb48eec96",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.849892Z",
     "start_time": "2024-02-25T05:21:27.836619Z"
    }
   },
   "outputs": [],
   "source": [
    "compiled_package = f\"{DIR}/compiled_pipeline_package.json\"\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func = vertex_ai_pipeline,\n",
    "    package_path = compiled_package\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5497c222-34c3-404a-870e-a522f5978c61",
   "metadata": {},
   "source": [
    "## 3. Execute the Pipeline on Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b9ccf19-78b7-49e0-b5e6-ec5c42f948cb",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.868517Z",
     "start_time": "2024-02-25T05:21:27.854653Z"
    }
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "46538bf4-0a85-49ca-bcc5-25dc523144d6",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:27.996260Z",
     "start_time": "2024-02-25T05:21:27.952007Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = f\"{APPNAME}\",\n",
    "    template_path = compiled_package,\n",
    "    pipeline_root=PIPELINE_URI,\n",
    "    parameter_values = {\n",
    "        \"project\": PROJECT,\n",
    "        \"region\": REGION,\n",
    "    },\n",
    "    #enable_caching = False,        #//TRUE, by default//\n",
    "    labels = {'notebook':f'{NOTEBOOK}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "SERVICE_ACCOUNT ='zacharynguyen@babyweight-mlops.iam.gserviceaccount.com'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T05:21:28.005352Z",
     "start_time": "2024-02-25T05:21:27.998046Z"
    }
   },
   "id": "8a2d63c4-d8c2-4016-a437-e0ddcba0f045",
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f2546555-2024-4d5a-8e83-6d76f45b7512",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-25T05:23:07.336465Z",
     "start_time": "2024-02-25T05:21:28.065488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/288906550115/locations/us-central1/pipelineJobs/babyweight-20240224232127\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/288906550115/locations/us-central1/pipelineJobs/babyweight-20240224232127')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/babyweight-20240224232127?project=288906550115\n",
      "PipelineJob projects/288906550115/locations/us-central1/pipelineJobs/babyweight-20240224232127 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/288906550115/locations/us-central1/pipelineJobs/babyweight-20240224232127 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/288906550115/locations/us-central1/pipelineJobs/babyweight-20240224232127 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/288906550115/locations/us-central1/pipelineJobs/babyweight-20240224232127 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [bq-table-prep-op].; Job (project_id = babyweight-mlops, job_id = 6751733944166645760) is failed due to the above error.; Failed to handle the job: {project_number = 288906550115, job_id = 6751733944166645760}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[104], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline_job\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mservice_account\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mSERVICE_ACCOUNT\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#sync = True\u001B[39;49;00m\n\u001B[1;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/39bw/lib/python3.9/site-packages/google/cloud/aiplatform/pipeline_jobs.py:323\u001B[0m, in \u001B[0;36mPipelineJob.run\u001B[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout)\u001B[0m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Run this configured PipelineJob and monitor the job until completion.\u001B[39;00m\n\u001B[1;32m    302\u001B[0m \n\u001B[1;32m    303\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;124;03m        Optional. The timeout for the create request in seconds.\u001B[39;00m\n\u001B[1;32m    320\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    321\u001B[0m network \u001B[38;5;241m=\u001B[39m network \u001B[38;5;129;01mor\u001B[39;00m initializer\u001B[38;5;241m.\u001B[39mglobal_config\u001B[38;5;241m.\u001B[39mnetwork\n\u001B[0;32m--> 323\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m    \u001B[49m\u001B[43mservice_account\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mservice_account\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnetwork\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreserved_ip_ranges\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreserved_ip_ranges\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m    \u001B[49m\u001B[43msync\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msync\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    328\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_request_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcreate_request_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    329\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/39bw/lib/python3.9/site-packages/google/cloud/aiplatform/base.py:817\u001B[0m, in \u001B[0;36moptional_sync.<locals>.optional_run_in_thread.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m    816\u001B[0m         VertexAiResourceNounWithFutureManager\u001B[38;5;241m.\u001B[39mwait(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 817\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    819\u001B[0m \u001B[38;5;66;03m# callbacks to call within the Future (in same Thread)\u001B[39;00m\n\u001B[1;32m    820\u001B[0m internal_callbacks \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/anaconda3/envs/39bw/lib/python3.9/site-packages/google/cloud/aiplatform/pipeline_jobs.py:366\u001B[0m, in \u001B[0;36mPipelineJob._run\u001B[0;34m(self, service_account, network, reserved_ip_ranges, sync, create_request_timeout)\u001B[0m\n\u001B[1;32m    340\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Helper method to ensure network synchronization and to run\u001B[39;00m\n\u001B[1;32m    341\u001B[0m \u001B[38;5;124;03mthe configured PipelineJob and monitor the job until completion.\u001B[39;00m\n\u001B[1;32m    342\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    357\u001B[0m \u001B[38;5;124;03m        Optional. The timeout for the create request in seconds.\u001B[39;00m\n\u001B[1;32m    358\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubmit(\n\u001B[1;32m    360\u001B[0m     service_account\u001B[38;5;241m=\u001B[39mservice_account,\n\u001B[1;32m    361\u001B[0m     network\u001B[38;5;241m=\u001B[39mnetwork,\n\u001B[1;32m    362\u001B[0m     reserved_ip_ranges\u001B[38;5;241m=\u001B[39mreserved_ip_ranges,\n\u001B[1;32m    363\u001B[0m     create_request_timeout\u001B[38;5;241m=\u001B[39mcreate_request_timeout,\n\u001B[1;32m    364\u001B[0m )\n\u001B[0;32m--> 366\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_block_until_complete\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/39bw/lib/python3.9/site-packages/google/cloud/aiplatform/pipeline_jobs.py:615\u001B[0m, in \u001B[0;36mPipelineJob._block_until_complete\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    612\u001B[0m \u001B[38;5;66;03m# Error is only populated when the job state is\u001B[39;00m\n\u001B[1;32m    613\u001B[0m \u001B[38;5;66;03m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001B[39;00m\n\u001B[1;32m    614\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gca_resource\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;129;01min\u001B[39;00m _PIPELINE_ERROR_STATES:\n\u001B[0;32m--> 615\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJob failed with:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gca_resource\u001B[38;5;241m.\u001B[39merror)\n\u001B[1;32m    616\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    617\u001B[0m     _LOGGER\u001B[38;5;241m.\u001B[39mlog_action_completed_against_resource(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrun\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompleted\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [bq-table-prep-op].; Job (project_id = babyweight-mlops, job_id = 6751733944166645760) is failed due to the above error.; Failed to handle the job: {project_number = 288906550115, job_id = 6751733944166645760}\"\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.run(\n",
    "    service_account = SERVICE_ACCOUNT,\n",
    "    #sync = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T05:23:07.344405Z",
     "start_time": "2024-02-25T05:23:07.340189Z"
    }
   },
   "id": "aaabc8ef00377061",
   "execution_count": null
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "vertexpip_env",
   "name": "workbench-notebooks.m115",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m115"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
